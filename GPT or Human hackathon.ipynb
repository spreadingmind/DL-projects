{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from IPython.display import clear_output\n","\n","!pip install transformers accelerate\n","!pip install datasets\n","!pip install wandb\n","# !pip install nlpaug\n","# !pip install sacremoses\n","# !pip install sentencepiece\n","# !pip install langdetect\n","\n","clear_output()"],"metadata":{"id":"Reuy1saBQVlG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wlzquq75PeTy"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from torch import cuda\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.nn.utils.rnn import pad_sequence\n","from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModel,\n","    BertModel,\n","    DataCollatorWithPadding,\n","    BertForSequenceClassification,\n","    BertForTokenClassification,\n","    AutoModelForMaskedLM,\n","    BertTokenizer,\n","    AutoModelForTokenClassification,\n","    pipeline,\n","    TrainingArguments,\n","    Trainer,\n","    BertConfig,\n","    EarlyStoppingCallback\n",")\n","\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive, output\n","from sklearn.metrics import f1_score\n","from tqdm.notebook import tqdm\n","import locale\n","from torch.nn import BCELoss, BCEWithLogitsLoss\n","# import wandb\n","import random\n","\n","# wandb.login()\n","\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding\n","\n","drive.mount('/content/drive', force_remount=True)\n","clear_output()"]},{"cell_type":"code","source":["WORK_FOLDER = 'drive/MyDrive/ML/GPT or Human'\n","DEVICE_NUM = 0\n","DEVICE = f\"cuda:{DEVICE_NUM}\" if cuda.is_available() else \"cpu\"\n","BATCH_SIZE = 16\n","EPOCHS=10"],"metadata":{"id":"Gd2RS3HJPwW0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(f'{WORK_FOLDER}/data/train.csv')"],"metadata":{"id":"ouY9JQm6WZsE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.drop(columns=['q_id', 'line_id'], inplace=True)\n","df['label'] = df['label'].map({'ai_answer': 1, 'hu_answer': 0}).values\n","df.head()"],"metadata":{"id":"lyDi02XWPxnp","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1686656947964,"user_tz":-180,"elapsed":8,"user":{"displayName":"Elisabeth Shevtsova","userId":"11550787371576167370"}},"outputId":"51ee55de-1721-4252-c515-677c01244f99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             q_title  label  \\\n","0  Какие комплектующие должны быть в компьютере, ...      0   \n","1  Какие комплектующие должны быть в компьютере, ...      1   \n","2      Loading a Reusable UITableViewCell from a Nib      1   \n","3      Loading a Reusable UITableViewCell from a Nib      0   \n","4             How can I change UIButton title color?      0   \n","\n","                                            ans_text  \n","0  Да ничего особенного. :)\\nКорпус должен быть, ...  \n","1  Здравствуйте! Спасибо за интересный вопрос. Дл...  \n","2  To load a reusable UITableViewCell from a Nib,...  \n","3  Actually, since you are building the cell in I...  \n","4  You can use -[UIButton setTitleColor:forState:...  "],"text/html":["\n","  <div id=\"df-3f7aa902-6708-4ecf-8954-af7a8e232506\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>q_title</th>\n","      <th>label</th>\n","      <th>ans_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Какие комплектующие должны быть в компьютере, ...</td>\n","      <td>0</td>\n","      <td>Да ничего особенного. :)\\nКорпус должен быть, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Какие комплектующие должны быть в компьютере, ...</td>\n","      <td>1</td>\n","      <td>Здравствуйте! Спасибо за интересный вопрос. Дл...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Loading a Reusable UITableViewCell from a Nib</td>\n","      <td>1</td>\n","      <td>To load a reusable UITableViewCell from a Nib,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Loading a Reusable UITableViewCell from a Nib</td>\n","      <td>0</td>\n","      <td>Actually, since you are building the cell in I...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>How can I change UIButton title color?</td>\n","      <td>0</td>\n","      <td>You can use -[UIButton setTitleColor:forState:...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f7aa902-6708-4ecf-8954-af7a8e232506')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3f7aa902-6708-4ecf-8954-af7a8e232506 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3f7aa902-6708-4ecf-8954-af7a8e232506');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)"],"metadata":{"id":"YzcEJyqkan80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["multi_lan_model = \"bert-base-multilingual-cased\"\n","multi_tokenizer = BertTokenizer.from_pretrained(multi_lan_model)\n","clear_output()"],"metadata":{"id":"AC9oHVzsWw2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenized_train = multi_tokenizer(\n","#     train_df[\"ans_text\"].tolist(),\n","#     padding=True,\n","#     truncation=True,\n","#     return_tensors=\"pt\"\n","# )\n","# train_input_ids, train_masks = (\n","#     tokenized_train[\"input_ids\"],\n","#     tokenized_train[\"attention_mask\"],\n","# )\n","# train_labels = torch.tensor(train_df[\"label\"].values).unsqueeze(-1)\n","\n","tokenized_valid = multi_tokenizer(\n","    valid_df[\"ans_text\"].tolist(),\n","    padding=True,\n","    truncation=True,\n","    return_tensors=\"pt\",\n",")\n","# valid_input_ids, valid_masks = (\n","#     tokenized_valid[\"input_ids\"],\n","#     tokenized_valid[\"attention_mask\"],\n","# )\n","# valid_labels = torch.tensor(valid_df[\"label\"].values).unsqueeze(-1)\n","\n","# # train_dataset = TensorDataset(train_input_ids, train_masks, train_labels)\n","# val_dataset = TensorDataset(valid_input_ids, valid_masks, valid_labels)"],"metadata":{"id":"X2-aA2mYXES0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_valid"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d78OLNzPlP9B","executionInfo":{"status":"ok","timestamp":1686656956742,"user_tz":-180,"elapsed":584,"user":{"displayName":"Elisabeth Shevtsova","userId":"11550787371576167370"}},"outputId":"df9e3837-4bf7-43ad-ffaf-b9290e9e420d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[   101,  11220,  10454,  ...,    121,    119,    102],\n","        [   101,    107, 105104,  ...,      0,      0,      0],\n","        [   101,    523,    117,  ...,      0,      0,      0],\n","        ...,\n","        [   101,  69345,  15597,  ...,  10297,  12709,    102],\n","        [   101,  11469,  13708,  ...,      0,      0,      0],\n","        [   101,    516,  35865,  ...,      0,      0,      0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## *Бейзлайн модель*"],"metadata":{"id":"9n0ML0VRJH2D"}},{"cell_type":"code","source":["# base_model = BertForSequenceClassification.from_pretrained(\n","#     multi_lan_model,\n","#     num_labels = 2,\n","#     output_attentions = False,\n","#     output_hidden_states = False\n","# )\n","\n","# base_model.to(DEVICE)\n","# clear_output()"],"metadata":{"id":"C43duDiaXqYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyDataCollator:\n","    def __call__(self, batch):\n","        return {\n","            \"input_ids\": torch.stack([t[0] for t in batch]),\n","            \"attention_mask\": torch.stack([t[1] for t in batch]),\n","            \"labels\": torch.stack([t[2] for t in batch]),\n","        }\n","\n","def f1_metric(preds):\n","    y_true = preds.label_ids\n","    y_pred = preds.predictions.argmax(-1)\n","    return {\"F1\": f1_score(y_true, y_pred)}\n","\n","\n","training_args = TrainingArguments(\n","    output_dir=f\"{WORK_FOLDER}/Runs/Base\",\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    logging_dir=f\"{WORK_FOLDER}/Runs\",\n","    remove_unused_columns=False,\n","    include_inputs_for_metrics=True,\n","    evaluation_strategy=\"steps\",\n","    save_strategy=\"steps\",\n","    eval_steps=500,\n","    save_total_limit=2,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"F1\",\n","    greater_is_better=True,\n",")"],"metadata":{"id":"cqtCbNw1Y0Ia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=base_model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=MyDataCollator(),\n","    compute_metrics=f1_metric\n",")\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":518},"id":"NklOsUu2eHrC","executionInfo":{"status":"ok","timestamp":1685551508857,"user_tz":-180,"elapsed":1586638,"user":{"displayName":"Tolik Kot","userId":"01323512671493298005"}},"outputId":"583cda64-f32b-4675-b0bb-7650d6c7a9fc"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230531_154131-izfzstv7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/liza-i-pivko/huggingface/runs/izfzstv7' target=\"_blank\">rosy-elevator-47</a></strong> to <a href='https://wandb.ai/liza-i-pivko/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/liza-i-pivko/huggingface' target=\"_blank\">https://wandb.ai/liza-i-pivko/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/liza-i-pivko/huggingface/runs/izfzstv7' target=\"_blank\">https://wandb.ai/liza-i-pivko/huggingface/runs/izfzstv7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1423' max='2410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1423/2410 37:02 < 25:43, 0.64 it/s, Epoch 5.90/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.162800</td>\n","      <td>0.192270</td>\n","      <td>0.955340</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.026000</td>\n","      <td>0.163972</td>\n","      <td>0.976143</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2410' max='2410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2410/2410 1:03:30, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.162800</td>\n","      <td>0.192270</td>\n","      <td>0.955340</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.026000</td>\n","      <td>0.163972</td>\n","      <td>0.976143</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.000000</td>\n","      <td>0.131455</td>\n","      <td>0.983017</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.000000</td>\n","      <td>0.141592</td>\n","      <td>0.983017</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2410, training_loss=0.03918642372654218, metrics={'train_runtime': 3817.0127, 'train_samples_per_second': 10.1, 'train_steps_per_second': 0.631, 'total_flos': 1.0142931184128e+16, 'train_loss': 0.03918642372654218, 'epoch': 10.0})"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["#### *Другие гиперпараметры у базовой модели*"],"metadata":{"id":"JzIB-9fBIt6i"}},{"cell_type":"code","source":["training_args.output_dir = f\"{WORK_FOLDER}/Runs/Base2\"\n","training_args.num_train_epochs = 15\n","training_args.weight_decay = 0.01\n","training_args.learning_rate = 1e-6\n","\n","trainer = Trainer(\n","    model=base_model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=MyDataCollator(),\n","    compute_metrics=f1_metric,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",")"],"metadata":{"id":"pBoC9VG3Dz2E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Скор упал*"],"metadata":{"id":"hvAEJydmJPfo"}},{"cell_type":"markdown","source":["##*Другой классификатор*"],"metadata":{"id":"xudBbaiPIll0"}},{"cell_type":"code","source":["class TwoLayerMLPClassifier(nn.Module):\n","    def __init__(self, hidden_size, num_classes, dropout_rate=0.1):\n","        super().__init__()\n","        self.layer1 = nn.Linear(hidden_size, hidden_size)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.layer2 = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.activation(x)\n","        x = self.dropout(x)\n","        x = self.layer2(x)\n","        return x"],"metadata":{"id":"hddZ4tEM0e5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model.classifier = TwoLayerMLPClassifier(base_model.config.hidden_size, 2)\n","\n","training_args.output_dir = f\"{WORK_FOLDER}/Runs/Class2\"\n","training_args.num_train_epochs = 15\n","training_args.weight_decay = 0.01\n","training_args.learning_rate = 1e-6\n","\n","trainer = Trainer(\n","    model=base_model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=MyDataCollator(),\n","    compute_metrics=f1_metric,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",")"],"metadata":{"id":"Ui0UNnuh14fd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"QcGomNi02FyZ","colab":{"base_uri":"https://localhost:8080/","height":463},"executionInfo":{"status":"ok","timestamp":1685724436910,"user_tz":-180,"elapsed":608347,"user":{"displayName":"Tolik Kot","userId":"01323512671493298005"}},"outputId":"1a070fe0-62fb-4fbc-f686-80dc27084994"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1615' max='3615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1615/3615 41:38 < 51:37, 0.65 it/s, Epoch 6.70/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.164400</td>\n","      <td>0.079431</td>\n","      <td>0.981057</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.016600</td>\n","      <td>0.061808</td>\n","      <td>0.984985</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.007300</td>\n","      <td>0.070297</td>\n","      <td>0.984000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='3615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/3615 51:48 < 41:52, 0.64 it/s, Epoch 8/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.164400</td>\n","      <td>0.079431</td>\n","      <td>0.981057</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.016600</td>\n","      <td>0.061808</td>\n","      <td>0.984985</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.007300</td>\n","      <td>0.070297</td>\n","      <td>0.984000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.004500</td>\n","      <td>0.078709</td>\n","      <td>0.984000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2000, training_loss=0.04819664597511292, metrics={'train_runtime': 3109.9205, 'train_samples_per_second': 18.594, 'train_steps_per_second': 1.162, 'total_flos': 8475491924656128.0, 'train_loss': 0.04819664597511292, 'epoch': 8.3})"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["*^ Это пока лучшая модель*"],"metadata":{"id":"dgB-jhXfI2wD"}},{"cell_type":"markdown","source":["## *Дисбаланс классов + бейзлайн / другой классификатор*"],"metadata":{"id":"eU_fS6gjHaWI"}},{"cell_type":"code","source":["train_df['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"al7WGXG4FtbV","executionInfo":{"status":"ok","timestamp":1686075914147,"user_tz":-180,"elapsed":6,"user":{"displayName":"Ivan Markin","userId":"00846858783230445907"}},"outputId":"4e5c2a3d-ab2f-4445-daa1-e6d28cd94c7c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    1932\n","0    1923\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["class_count_1, class_count_0 = train_df['label'].value_counts()\n","\n","class_0 = train_df[train_df['label'] == 0]\n","class_1 = train_df[train_df['label'] == 1]\n","\n","class_0_over = class_0.sample(class_count_1, replace=True)\n","\n","train_df_balanced = pd.concat([\n","    class_0_over, class_1\n","    ], axis=0).sample(frac=1)"],"metadata":{"id":"tra4RBsRFMZb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df_balanced['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnzR8TTZGAwe","executionInfo":{"status":"ok","timestamp":1686075914147,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ivan Markin","userId":"00846858783230445907"}},"outputId":"844c816e-1e14-4651-cc00-368ce74653b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    1932\n","1    1932\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["tokenized_train = multi_tokenizer(\n","    train_df_balanced[\"ans_text\"].tolist(),\n","    padding=True,\n","    truncation=True,\n","    return_tensors=\"pt\"\n",")\n","train_input_ids, train_masks = (\n","    tokenized_train[\"input_ids\"],\n","    tokenized_train[\"attention_mask\"],\n",")\n","train_labels = torch.tensor(train_df_balanced[\"label\"].values).unsqueeze(-1)\n","train_dataset = TensorDataset(train_input_ids, train_masks, train_labels)"],"metadata":{"id":"yx21IQLtHwpn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = BertForSequenceClassification.from_pretrained(\n","    multi_lan_model,\n","    num_labels = 2,\n","    output_attentions = False,\n","    output_hidden_states = False\n",")\n","\n","base_model.to(DEVICE)\n","clear_output()\n","\n","training_args.output_dir = f\"{WORK_FOLDER}/Runs/Base4\"\n","training_args.num_train_epochs = 30\n","training_args.weight_decay = 0.01\n","training_args.learning_rate = 1e-6\n","\n","trainer = Trainer(\n","    model=base_model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=MyDataCollator(),\n","    compute_metrics=f1_metric,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n","\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"nEp9AV7KenHz","outputId":"5b603bd7-d74f-4464-b1cf-a1c5a63f106b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230606_182535-ezesktwb</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/liza-i-pivko/huggingface/runs/ezesktwb' target=\"_blank\">drive/MyDrive/ML/GPT or Human/Runs/Base</a></strong> to <a href='https://wandb.ai/liza-i-pivko/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/liza-i-pivko/huggingface' target=\"_blank\">https://wandb.ai/liza-i-pivko/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/liza-i-pivko/huggingface/runs/ezesktwb' target=\"_blank\">https://wandb.ai/liza-i-pivko/huggingface/runs/ezesktwb</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1001' max='7260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1001/7260 25:46 < 2:41:31, 0.65 it/s, Epoch 4.13/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.407700</td>\n","      <td>0.333023</td>\n","      <td>0.893773</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='51' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [51/61 00:27 < 00:05, 1.84 it/s]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["trainer.train(f\"{WORK_FOLDER}/Runs/Base2/checkpoint-2000\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"id":"7aFSQYWKzXI5","executionInfo":{"status":"ok","timestamp":1685789666229,"user_tz":-180,"elapsed":639857,"user":{"displayName":"Elisabeth Shevtsova","userId":"11550787371576167370"}},"outputId":"4839f776-60f3-4f1b-8ac0-11a89b248b51"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2410' max='2410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2410/2410 10:33, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2410, training_loss=3.891109384565433e-06, metrics={'train_runtime': 634.6782, 'train_samples_per_second': 60.739, 'train_steps_per_second': 3.797, 'total_flos': 1.0142931184128e+16, 'train_loss': 3.891109384565433e-06, 'epoch': 10.0})"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"hc_Xcee25oYe","executionInfo":{"status":"ok","timestamp":1686047278656,"user_tz":-180,"elapsed":32784,"user":{"displayName":"Ivan Markin","userId":"00846858783230445907"}},"outputId":"a2e52a3e-6951-4d43-e66b-0ec73476bd02"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [61/61 00:32]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.1908539980649948,\n"," 'eval_F1': 0.9752229930624381,\n"," 'eval_runtime': 32.6148,\n"," 'eval_samples_per_second': 29.557,\n"," 'eval_steps_per_second': 1.87,\n"," 'epoch': 20.0}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["trainer.save_model(f\"{WORK_FOLDER}/Runs/Base2/maybe_better_cls_balanced\")"],"metadata":{"id":"4upR4-L_62Yd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for param in base_model.base_model.parameters():\n","#     param.requires_grad = False\n","\n","base_model.classifier = TwoLayerMLPClassifier(base_model.config.hidden_size, 2)\n","\n","training_args.output_dir = f\"{WORK_FOLDER}/Runs/Class4\"\n","training_args.num_train_epochs = 30\n","training_args.weight_decay = 0.01\n","training_args.learning_rate = 1e-6\n","\n","trainer = Trainer(\n","    model=base_model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=MyDataCollator(),\n","    compute_metrics=f1_metric,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OtsTcBf0Hy_9","executionInfo":{"status":"error","timestamp":1686075617196,"user_tz":-180,"elapsed":505214,"user":{"displayName":"Ivan Markin","userId":"00846858783230445907"}},"outputId":"d0d751b3-4eba-45ce-8480-2cee1245a165"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlisabeth-shevtsova\u001b[0m (\u001b[33mliza-i-pivko\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230606_164808-6hgzxhnu</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/liza-i-pivko/huggingface/runs/6hgzxhnu' target=\"_blank\">drive/MyDrive/ML/GPT or Human/Runs/Base</a></strong> to <a href='https://wandb.ai/liza-i-pivko/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/liza-i-pivko/huggingface' target=\"_blank\">https://wandb.ai/liza-i-pivko/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/liza-i-pivko/huggingface/runs/6hgzxhnu' target=\"_blank\">https://wandb.ai/liza-i-pivko/huggingface/runs/6hgzxhnu</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3145' max='7260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3145/7260 1:23:36 < 1:49:28, 0.63 it/s, Epoch 12.99/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.607400</td>\n","      <td>0.405490</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.354800</td>\n","      <td>0.251672</td>\n","      <td>0.920152</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.183900</td>\n","      <td>0.213309</td>\n","      <td>0.939013</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.098300</td>\n","      <td>0.174511</td>\n","      <td>0.952102</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.058700</td>\n","      <td>0.219478</td>\n","      <td>0.951267</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.045700</td>\n","      <td>0.246394</td>\n","      <td>0.948693</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3479' max='7260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3479/7260 1:31:59 < 1:40:02, 0.63 it/s, Epoch 14.37/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.607400</td>\n","      <td>0.405490</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.354800</td>\n","      <td>0.251672</td>\n","      <td>0.920152</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.183900</td>\n","      <td>0.213309</td>\n","      <td>0.939013</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.098300</td>\n","      <td>0.174511</td>\n","      <td>0.952102</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.058700</td>\n","      <td>0.219478</td>\n","      <td>0.951267</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.045700</td>\n","      <td>0.246394</td>\n","      <td>0.948693</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 21>\u001b[0m:\u001b[94m21\u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1664\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1664 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1666 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1667 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1940\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m model.no_sync():                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1938 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1940 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1942 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1943 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2753\u001b[0m in \u001b[92mtraining_step\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2750 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# loss gets scaled under gradient_accumulation_steps in deepspeed\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2751 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.deepspeed.backward(loss)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2752 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2753 \u001b[2m│   │   │   \u001b[0mloss.backward()                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2754 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2755 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loss.detach()                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2756 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 21&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">21</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1662 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1665 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1666 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1667 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1940</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> model.no_sync():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1938 │   │   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1940 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1942 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1943 │   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2753</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2750 │   │   │   # loss gets scaled under gradient_accumulation_steps in deepspeed</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2751 │   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.deepspeed.backward(loss)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2752 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2753 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2754 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2755 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss.detach()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2756 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# play notification :D\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"],"metadata":{"id":"3LLHSovpnD2r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## *Языки*"],"metadata":{"id":"UX8lwiGhKn_K"}},{"cell_type":"code","source":["from langdetect import detect"],"metadata":{"id":"sfmDMrWzKLmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_langs = train_df_balanced['ans_text'].apply(detect)\n","train_langs.value_counts()"],"metadata":{"id":"5yW8uMbuKV6M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685965111712,"user_tz":-180,"elapsed":33969,"user":{"displayName":"Tolik Kot","userId":"01323512671493298005"}},"outputId":"c5666ea5-df52-43c1-cf79-0c22159f5a51"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["en    2170\n","ru    1691\n","ca       3\n","Name: ans_text, dtype: int64"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["train_df_balanced['lang'] = train_langs\n","train_df_balanced['lang'] = train_df_balanced['lang'].apply(lambda l: 'en' if l != 'ru' else 'ru')\n","\n","train_df_balanced.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"lv6LvLnGG9K9","executionInfo":{"status":"ok","timestamp":1685965111713,"user_tz":-180,"elapsed":26,"user":{"displayName":"Tolik Kot","userId":"01323512671493298005"}},"outputId":"6b5e5943-60ac-43b4-efcc-dd5c4406c581"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                q_title  label  \\\n","2246  Can multithreading be implemented on a single ...      1   \n","1498  How do I get the intersection between two arra...      1   \n","2880  Есть ли что-то из классической литературы, что...      0   \n","1031          iOS app error - Can't add self as subview      0   \n","1313  Какую книгу для подростков 14-15 лет вы считае...      0   \n","\n","                                               ans_text lang  \n","2246  Yes, multithreading can be implemented on a si...   en  \n","1498  Well, well, well, looks like someone needs to ...   en  \n","2880  Примерно раз в 5 лет перечитываю всего Оскара ...   ru  \n","1031  I am speculating based on something similar th...   en  \n","1313  Помню как (правда, это было уже на пороге 16 л...   ru  "],"text/html":["\n","  <div id=\"df-3eb5feb9-807b-48b2-86a3-17d6d5be2563\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>q_title</th>\n","      <th>label</th>\n","      <th>ans_text</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2246</th>\n","      <td>Can multithreading be implemented on a single ...</td>\n","      <td>1</td>\n","      <td>Yes, multithreading can be implemented on a si...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>1498</th>\n","      <td>How do I get the intersection between two arra...</td>\n","      <td>1</td>\n","      <td>Well, well, well, looks like someone needs to ...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>2880</th>\n","      <td>Есть ли что-то из классической литературы, что...</td>\n","      <td>0</td>\n","      <td>Примерно раз в 5 лет перечитываю всего Оскара ...</td>\n","      <td>ru</td>\n","    </tr>\n","    <tr>\n","      <th>1031</th>\n","      <td>iOS app error - Can't add self as subview</td>\n","      <td>0</td>\n","      <td>I am speculating based on something similar th...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>1313</th>\n","      <td>Какую книгу для подростков 14-15 лет вы считае...</td>\n","      <td>0</td>\n","      <td>Помню как (правда, это было уже на пороге 16 л...</td>\n","      <td>ru</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3eb5feb9-807b-48b2-86a3-17d6d5be2563')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3eb5feb9-807b-48b2-86a3-17d6d5be2563 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3eb5feb9-807b-48b2-86a3-17d6d5be2563');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["train_df_balanced.lang.unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mm5-SpdOI4_J","executionInfo":{"status":"ok","timestamp":1685965479924,"user_tz":-180,"elapsed":399,"user":{"displayName":"Tolik Kot","userId":"01323512671493298005"}},"outputId":"ffb47d22-f703-459d-bd75-5e872406e5ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['en', 'ru'], dtype=object)"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["## *Augmentation*"],"metadata":{"id":"bRDi1D9LBGbu"}},{"cell_type":"code","source":["import nlpaug.augmenter.char as nac\n","import nlpaug.augmenter.word as naw\n","import nlpaug.augmenter.sentence as nas\n","import nlpaug.flow as nafc\n","\n","from nlpaug.util import Action"],"metadata":{"id":"iZyVTfwCBIIo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["back_translation_aug_ru = naw.BackTranslationAug(\n","    from_model_name='Helsinki-NLP/opus-mt-ru-en',\n","    to_model_name='Helsinki-NLP/opus-mt-en-ru',\n","    device=DEVICE,\n","    batch_size=8\n",")\n","\n","clear_output()\n","\n","class_rus = train_df_balanced[train_df_balanced.lang == 'ru'].copy()\n","aug_rus = back_translation_aug_ru.augment(class_rus.ans_text.to_list())"],"metadata":{"id":"biNKS2Z2B6eR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# play notification :D\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"],"metadata":{"id":"D-Vg7cHBSKVc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"5mp0T820eE0D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["back_translation_aug_en = naw.BackTranslationAug(\n","    from_model_name='Helsinki-NLP/opus-mt-en-ru',\n","    to_model_name='Helsinki-NLP/opus-mt-ru-en',\n","    device=DEVICE,\n","    batch_size=8\n",")\n","class_eng = train_df_balanced[train_df_balanced.lang == 'en'].copy()\n","aug_eng = back_translation_aug_en.augment(class_eng.ans_text.to_list())"],"metadata":{"id":"2u0g7mzqMe07"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"gBq8l1qRpBeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"],"metadata":{"id":"sesf2W6Se-xo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_rus['ans_text'] = aug_rus\n","class_eng['ans_text'] = aug_eng"],"metadata":{"id":"Ci0bAr5ENFQh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df_balanced_aug = pd.concat([train_df_balanced, class_rus, class_eng]).sample(frac=1).reset_index(drop=True)\n","train_df_balanced_aug.to_csv(f\"{WORK_FOLDER}/train_df_balanced_aug.csv\")"],"metadata":{"id":"1sf9xCrVoelY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df_balanced_aug = pd.read_csv(f\"{WORK_FOLDER}/train_df_balanced_aug.csv\")"],"metadata":{"id":"PRxw7RumrbrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_train = multi_tokenizer(\n","    train_df_balanced_aug[\"ans_text\"].tolist(),\n","    padding=True,\n","    truncation=True,\n","    return_tensors=\"pt\"\n",")\n","train_input_ids, train_masks = (\n","    tokenized_train[\"input_ids\"],\n","    tokenized_train[\"attention_mask\"],\n",")\n","train_labels = torch.tensor(train_df_balanced_aug[\"label\"].values).unsqueeze(-1)\n","train_dataset = TensorDataset(train_input_ids, train_masks, train_labels)\n","\n","base_model = BertForSequenceClassification.from_pretrained(\n","    multi_lan_model,\n","    num_labels = 2,\n","    output_attentions = False,\n","    output_hidden_states = False\n",")\n","\n","base_model.to(DEVICE)\n","clear_output()\n","\n","training_args.output_dir = f\"{WORK_FOLDER}/Runs/Base4\"\n","training_args.num_train_epochs = 10\n","\n","trainer = Trainer(\n","    model=base_model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=MyDataCollator(),\n","    compute_metrics=f1_metric,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",")"],"metadata":{"id":"JoaoKZIoo03_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675},"id":"5hXFKqxrp5oQ","executionInfo":{"status":"ok","timestamp":1685975556435,"user_tz":-180,"elapsed":658819,"user":{"displayName":"Tolik Kot","userId":"01323512671493298005"}},"outputId":"afe2d2bc-2731-4a6b-ba1e-333547c4bb33"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230605_131111-9jbya398</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/liza-i-pivko/huggingface/runs/9jbya398' target=\"_blank\">drive/MyDrive/ML/GPT or Human/Runs/Base</a></strong> to <a href='https://wandb.ai/liza-i-pivko/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/liza-i-pivko/huggingface' target=\"_blank\">https://wandb.ai/liza-i-pivko/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/liza-i-pivko/huggingface/runs/9jbya398' target=\"_blank\">https://wandb.ai/liza-i-pivko/huggingface/runs/9jbya398</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2603' max='4830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2603/4830 1:10:17 < 1:00:11, 0.62 it/s, Epoch 5.39/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.245300</td>\n","      <td>0.125210</td>\n","      <td>0.964567</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.057100</td>\n","      <td>0.252380</td>\n","      <td>0.960938</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.027100</td>\n","      <td>0.136579</td>\n","      <td>0.974155</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.014500</td>\n","      <td>0.190755</td>\n","      <td>0.973081</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.014000</td>\n","      <td>0.276504</td>\n","      <td>0.967552</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3000' max='4830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3000/4830 1:21:17 < 49:37, 0.61 it/s, Epoch 6/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.245300</td>\n","      <td>0.125210</td>\n","      <td>0.964567</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.057100</td>\n","      <td>0.252380</td>\n","      <td>0.960938</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.027100</td>\n","      <td>0.136579</td>\n","      <td>0.974155</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.014500</td>\n","      <td>0.190755</td>\n","      <td>0.973081</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.014000</td>\n","      <td>0.276504</td>\n","      <td>0.967552</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.002400</td>\n","      <td>0.298018</td>\n","      <td>0.966535</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3000, training_loss=0.06007338134447734, metrics={'train_runtime': 4884.3315, 'train_samples_per_second': 15.822, 'train_steps_per_second': 0.989, 'total_flos': 1.262933065728e+16, 'train_loss': 0.06007338134447734, 'epoch': 6.21})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"],"metadata":{"id":"T2R-wOYlsP5R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## *SCRIPT FOR INFERENCE*"],"metadata":{"id":"snR6iHhx3FHP"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","from transformers import BertForSequenceClassification, BertTokenizer\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","\n","class TwoLayerMLPClassifier(nn.Module):\n","    def __init__(self, hidden_size, num_classes, dropout_rate=0.1):\n","        super().__init__()\n","        self.layer1 = nn.Linear(hidden_size, hidden_size)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.layer2 = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.activation(x)\n","        x = self.dropout(x)\n","        x = self.layer2(x)\n","        return x\n","\n","\n","class CustomBertForSequenceClassification(BertForSequenceClassification):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.classifier = TwoLayerMLPClassifier(\n","            self.bert.config.hidden_size, self.num_labels)\n","\n","\n","MULTI_LANG_BERT = \"bert-base-multilingual-cased\"\n","\n","if __name__ == \"__main__\":\n","    df_test = pd.read_csv(f\"{WORK_FOLDER}/data/train.csv\")\n","    multi_tokenizer = BertTokenizer.from_pretrained(\n","        MULTI_LANG_BERT, model_max_length=512)\n","    tokenized_test = multi_tokenizer(\n","        df_test[\"ans_text\"].tolist(),\n","        padding=True,\n","        truncation=True,\n","        return_tensors=\"pt\",\n","    )\n","    test_input_ids, test_masks = (\n","        tokenized_test[\"input_ids\"],\n","        tokenized_test[\"attention_mask\"],\n","    )\n","    test_dataset = TensorDataset(test_input_ids, test_masks)\n","    loader = DataLoader(test_dataset, batch_size=256)\n","\n","    model = CustomBertForSequenceClassification.from_pretrained(\n","        f\"{WORK_FOLDER}/Runs/Class2/checkpoint-1000\",\n","        num_labels=2,\n","        output_attentions=False,\n","        output_hidden_states=False\n","    )\n","    model.to(\"cuda\")\n","    with torch.no_grad():\n","        predictions = []\n","        for batch in loader:\n","            test_input_ids, test_masks = batch\n","            outputs = model(\n","                test_input_ids.to(\"cuda\"),\n","                test_masks.to(\"cuda\"),\n","            )\n","            predictions.append(outputs.logits.argmax(-1).cpu())\n","        df_test[\"label\"] = torch.cat(predictions, dim=0).numpy()\n","        df_test[\"label\"] = df_test[\"label\"].map(\n","            {1: 'ai_answer', 0: 'hu_answer'})\n","        df_test[[\"line_id\", \"label\"]].to_csv(\n","            f\"{WORK_FOLDER}/data/submission.csv\", sep=\",\", index=False)\n"],"metadata":{"id":"MgxO1pngjWe_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"SPeADVXCXC9P"},"execution_count":null,"outputs":[]}]}